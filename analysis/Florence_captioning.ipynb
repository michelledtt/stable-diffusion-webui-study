{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b621a4ba-2ee8-420b-a054-611a7f7d36d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c917dbdc-fa88-42fa-857e-de719442cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8472f40e8845f4ab740b06e6c53b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a858a02cade849a5bb0abc368e6d35c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_florence2.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base:\n",
      "- configuration_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cc6e0f332e475cb4ff40bb48465f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_florence2.py:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base:\n",
      "- modeling_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eab9734dd6a4e8da330ce40fb6b7a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/464M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6809412c8e84404aab32d71ada388a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee0f4ee9ed1455a8fa5a29a0fe47591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_florence2.py:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large:\n",
      "- processing_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581dbb54913b4aa59903d13c9f50197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed344bc310b0418e8c4ee5f10c4e14b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de6c8d55bbe42f2a56dc3488f5f6e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OD>': {'bboxes': [[34.23999786376953, 160.0800018310547, 597.4400024414062, 371.7599792480469], [272.32000732421875, 241.67999267578125, 303.67999267578125, 247.4399871826172], [454.0799865722656, 276.7200012207031, 553.9199829101562, 370.79998779296875], [96.31999969482422, 280.55999755859375, 198.0800018310547, 371.2799987792969]], 'labels': ['car', 'door handle', 'wheel', 'wheel']}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "#workaround for unnecessary flash_attn requirement\n",
    "import os\n",
    "from unittest.mock import patch\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "from typing import Union, List\n",
    "\n",
    "def fixed_get_imports(filename: Union[str, os.PathLike]) -> List[str]:\n",
    "    if not str(filename).endswith(\"/modeling_florence2.py\"):\n",
    "        return get_imports(filename)\n",
    "    imports = get_imports(filename)\n",
    "    imports.remove(\"flash_attn\")\n",
    "    return imports\n",
    "\n",
    "\n",
    "with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports): #workaround for unnecessary flash_attn requirement\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-base\",trust_remote_code=True)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)\n",
    "\n",
    "prompt = \"<OD>\"\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=1024,\n",
    "    num_beams=3,\n",
    "    do_sample=False\n",
    ")\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=\"<OD>\", image_size=(image.width, image.height))\n",
    "\n",
    "print(parsed_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b43fcc9-9b56-4f54-adec-2d57cae257d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s><s>car<loc_53><loc_333><loc_933><loc_774>door handle<loc_425><loc_503><loc_474><loc_515>wheel<loc_709><loc_576><loc_865><loc_772><loc_150><loc_584><loc_309><loc_773></s>\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75a6e61-a47e-49f0-a5a7-e3c7ac30e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(task_prompt, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(\n",
    "      input_ids=inputs[\"input_ids\"],\n",
    "      pixel_values=inputs[\"pixel_values\"],\n",
    "      max_new_tokens=1024,\n",
    "      num_beams=3\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    parsed_answer = processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
    "\n",
    "    print(parsed_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da2d71ca-6853-48cc-8c12-3bef0b71f5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<CAPTION>': '\\nA green car parked in front of a yellow building.\\n'}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<CAPTION>\"\n",
    "run_example(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc6aaeb3-7bae-4c56-8b93-1344bd76fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A green car parked in front of a yellow building.\n"
     ]
    }
   ],
   "source": [
    "def filter_caption(output):\n",
    "    return output.get('<CAPTION>', '').strip()\n",
    "\n",
    "# Example usage\n",
    "output = {'<CAPTION>': '\\nA green car parked in front of a yellow building.\\n'}\n",
    "caption = filter_caption(output)\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0255a6-0b9b-44ac-a372-479f7a4688e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_captions(input, output, folder_path):\n",
    "    with open(output, 'w') as output_file: \n",
    "        # Loop through the image files and open each one\n",
    "        for image_file in input:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            with Image.open(image_path) as image:\n",
    "                inputs = processor(text='<CAPTION>', images=image, return_tensors=\"pt\")\n",
    "                generated_ids = model.generate(\n",
    "                    input_ids=inputs[\"input_ids\"],\n",
    "                    pixel_values=inputs[\"pixel_values\"],\n",
    "                    max_new_tokens=1024,\n",
    "                    num_beams=3,\n",
    "                    do_sample=False\n",
    "                )\n",
    "                generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "                parsed_answer = processor.post_process_generation(generated_text, task='<CAPTION>', image_size=(image.width, image.height))\n",
    "                parsed_answer = parsed_answer.get('<CAPTION>', '').strip()\n",
    "                output_file.write(f\"{parsed_answer}\\n\")\n",
    "\n",
    "folder_path_story = '/Users/mimi/Desktop/internship/study/all_images_story'\n",
    "story_files = os.listdir(folder_path_story)\n",
    "story_image_files = [f for f in story_files if f.lower().endswith(('.png'))]\n",
    "generate_image_captions(story_image_files, '/Users/mimi/Desktop/internship/study/story_image_captions_florence.txt',folder_path_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3faa1450-3582-4122-b3ae-adf19703c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_sound = '/Users/mimi/Desktop/internship/study/all_images_sound'\n",
    "sound_files = os.listdir(folder_path_sound)\n",
    "sound_image_files = [f for f in sound_files if f.lower().endswith(('.png'))]\n",
    "generate_image_captions(sound_image_files, '/Users/mimi/Desktop/internship/study/sound_image_captions_florence.txt',folder_path_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cbe92-1839-474b-a3d8-f8352ad85008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
